{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Manan, it's nice to meet you! \\n\\nThat's great to hear - AI Engineering is a really exciting field right now. What aspects of AI engineering are you most interested in? \\n\\nDo you have any specific projects or areas you're looking to learn more about? I'm happy to chat about anything related to AI, from machine learning algorithms to the ethical considerations of AI development.\\n\", response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 28, 'total_tokens': 116, 'completion_time': 0.181927877, 'prompt_time': 0.002605798, 'queue_time': None, 'total_time': 0.18453367499999998}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6629a15c-9f71-41f8-b132-d5fd8c20f001-0', usage_metadata={'input_tokens': 28, 'output_tokens': 88, 'total_tokens': 116})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "llm.invoke([HumanMessage(\"Hello, my name is Manan and I am an aspiring AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Manan, and you aspire to be an AI Engineer! üòä  \\n\\nIs there anything else you'd like to talk about related to AI or your aspirations?  I'm happy to chat. \\n\", response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 183, 'total_tokens': 234, 'completion_time': 0.105365789, 'prompt_time': 0.009475583, 'queue_time': None, 'total_time': 0.114841372}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0bfa7e90-28d9-45a4-ae01-fd91320d6cdd-0', usage_metadata={'input_tokens': 183, 'output_tokens': 51, 'total_tokens': 234})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(\"Hello, my name is Manan and I am an aspiring AI Engineer\"),\n",
    "    AIMessage(\"Hello Manan, it's nice to meet you!  \\n\\nThat's great you're interested in AI Engineering. It's a rapidly growing and exciting field. \\n\\nDo you have any specific questions about AI engineering that I can help you with? \\n\\nPerhaps you're curious about:\\n\\n* **Different areas of AI engineering?** (e.g., machine learning, computer vision, natural language processing)\\n* **Required skills and education?**\\n* **Resources for learning AI?**\\n* **Current trends and challenges in the field?**\\n\\n\\nI'm here to help in any way I can!\\n\"),\n",
    "    HumanMessage(\"What's my name and what do I aspire to be?\")\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "model_with_history = RunnableWithMessageHistory(llm, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Manan, it's nice to meet you!  Computer Engineering is a fascinating field. What are you most interested in learning about within computer engineering? üòä \\n\\nPerhaps you're interested in:\\n\\n* **Hardware design?**\\n* **Software development?**\\n* **Artificial intelligence?**\\n* **Cybersecurity?**\\n* **Robotics?**\\n\\nTell me more about your studies!  I'd love to hear what you're working on.\\n\", response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 25, 'total_tokens': 126, 'completion_time': 0.209296787, 'prompt_time': 0.002597729, 'queue_time': None, 'total_time': 0.211894516}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b93cd8a4-100b-40ae-8949-07692b177174-0', usage_metadata={'input_tokens': 25, 'output_tokens': 101, 'total_tokens': 126})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model_with_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is Manan, I study Computer Engineering\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's a fun question!  \\n\\nBased on our conversation, I know that:\\n\\n* **Your name is Manan.**\\n* **You study Computer Engineering.**\\n\\nYou're clearly someone who's interested in technology and how things work.  \\n\\nBut who are you beyond those facts? What are your hobbies?  What are your dreams for the future?  What makes you, *you*? \\n\\nI'm eager to learn more! üòä  \\n\\n\\n\\n\\n\", response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 138, 'total_tokens': 238, 'completion_time': 0.207800299, 'prompt_time': 0.012178972, 'queue_time': None, 'total_time': 0.219979271}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e591e382-18d8-4ec6-a6ca-8ee22d7e5930-0', usage_metadata={'input_tokens': 138, 'output_tokens': 100, 'total_tokens': 238})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_history.invoke(\n",
    "    [HumanMessage(content=\"Who am I?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have access to any personal information about you, so I don't know who you are.\\n\\nIf you'd like to tell me about yourself, I'm happy to listen!\\n\", response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 18, 'total_tokens': 67, 'completion_time': 0.100242421, 'prompt_time': 0.002352569, 'queue_time': None, 'total_time': 0.10259499}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1e9e4499-08e8-4db4-8a55-954aa0986c39-0', usage_metadata={'input_tokens': 18, 'output_tokens': 49, 'total_tokens': 67})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_history.invoke(\n",
    "    [HumanMessage(content=\"Who am I?\")],\n",
    "    config={\"configurable\": {\"session_id\": \"chat2\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello John! It's nice to meet you.  \\n\\nWhat can I do for you today? üòä  \\n\\n\", response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 78, 'total_tokens': 105, 'completion_time': 0.054062624, 'prompt_time': 0.004513047, 'queue_time': None, 'total_time': 0.058575670999999996}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e3076d94-78f4-4854-999f-4e0d9cc811bc-0', usage_metadata={'input_tokens': 78, 'output_tokens': 27, 'total_tokens': 105})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_history.invoke(\n",
    "    [HumanMessage(content=\"I am John\")],\n",
    "    config={\"configurable\": {\"session_id\": \"chat2\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are John!  We established that a moment ago. üòä \\n\\nIs there something specific you'd like to know about yourself, or are you just curious?  I'm here to help in any way I can. \\n\\n\", response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 116, 'total_tokens': 168, 'completion_time': 0.107157627, 'prompt_time': 0.006515545, 'queue_time': None, 'total_time': 0.113673172}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8cd86a65-1b7a-4226-b75b-f68718d5cc8f-0', usage_metadata={'input_tokens': 116, 'output_tokens': 52, 'total_tokens': 168})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_history.invoke(\n",
    "    [HumanMessage(content=\"Who am I?\")],\n",
    "    config={\"configurable\": {\"session_id\": \"chat2\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer the questions to the best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Andrew, it's nice to meet you!\\n\\nWhat can I do for you today? üòä  \\n\", response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 35, 'total_tokens': 60, 'completion_time': 0.050101776, 'prompt_time': 0.003258217, 'queue_time': None, 'total_time': 0.053359993}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-de15df16-d14a-442c-ac4d-520c04698316-0', usage_metadata={'input_tokens': 35, 'output_tokens': 25, 'total_tokens': 60})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [HumanMessage(\"Hi my name is Andrew\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Andrew, it's nice to meet you!\\n\\nIs there anything I can help you with today? üòä  \\n\\n\", response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 35, 'total_tokens': 63, 'completion_time': 0.056636402, 'prompt_time': 0.003304548, 'queue_time': None, 'total_time': 0.05994095}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8c4bafbe-dfca-4b24-a259-1c27765f81d3-0', usage_metadata={'input_tokens': 35, 'output_tokens': 28, 'total_tokens': 63})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(\"Hi my name is Andrew\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's a fun question! \\n\\nBased on our conversation, you are Andrew, a person who is interacting with me, a helpful AI assistant. \\n\\nIs there anything else you'd like to tell me about yourself?  üòÑ \\n\\n\\n\\n\\n\", response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 74, 'total_tokens': 128, 'completion_time': 0.111035595, 'prompt_time': 0.005014656, 'queue_time': None, 'total_time': 0.11605025100000001}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-40ae3fca-e44a-42f4-8371-52ad9dddc128-0', usage_metadata={'input_tokens': 74, 'output_tokens': 54, 'total_tokens': 128})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(\"Who am I?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer the questions to the best of your ability in {language}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], template='You are a helpful assistant. Answer the questions to the best of your ability in {language}.')), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000199B4A3FB50>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000199B4A0F7C0>, model_name='Gemma2-9b-It', groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§®‡§Æ‡§∏‡•ç‡§§‡•á Manan! üòä\\n\\n‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§∏‡•á ‡§Æ‡§ø‡§≤‡§ï‡§∞ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≤‡§ó‡§æ‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•ã‡§à ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å? \\n', response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 37, 'total_tokens': 70, 'completion_time': 0.066830854, 'prompt_time': 0.002998808, 'queue_time': None, 'total_time': 0.069829662}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8e2c831e-e7b7-4b08-ba45-d5ebffadc5b7-0', usage_metadata={'input_tokens': 37, 'output_tokens': 33, 'total_tokens': 70})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "    \"messages\": [HumanMessage(\"My name is Manan\")],\n",
    "    \"language\": \"Hindi\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§Ü‡§™ ‡§è‡§Ç‡§°‡•ç‡§∞‡§Ø‡•Ç ‡§π‡•à‡§Ç!  \\n\\n‡§Ü‡§™‡§®‡•á ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§•‡§æ ‡§ï‡§ø ‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§è‡§Ç‡§°‡•ç‡§∞‡§Ø‡•Ç ‡§π‡•à‡•§ üòä  \\n\\n‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡•á ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§¨‡§§‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á? \\n', response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 141, 'total_tokens': 186, 'completion_time': 0.094402845, 'prompt_time': 0.012229572, 'queue_time': None, 'total_time': 0.106632417}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0ceeefd-ffbe-47f0-abe1-a9334a8d2aa3-0', usage_metadata={'input_tokens': 141, 'output_tokens': 45, 'total_tokens': 186})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(\"Who am I?\")], \"language\": \"Hindi\"},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 70,\n",
    "    strategy = \"last\",\n",
    "    token_counter = llm,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer) | prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and don't know your name. Could you tell me? üòä  \\n\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what's my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"abc20\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations or access to personal information about you. So I don't know your name. üòä\\n\\nIf you'd like to tell me your name, I'd be happy to know!\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's delve into bagging techniques in machine learning.\n",
      "\n",
      "**Bagging: Boosting Your Model's Performance**\n",
      "\n",
      "Bagging, short for **Bootstrap Aggregating**, is a powerful ensemble learning technique used to improve the stability and accuracy of machine learning models.  \n",
      "\n",
      "**Here's how it works:**\n",
      "\n",
      "1. **Bootstrap Sampling:**\n",
      "\n",
      "   - Imagine you have a training dataset. Bagging starts by repeatedly drawing random samples (with replacement) from this dataset.  Each sample is called a \"bootstrap sample,\" and it's the same size as the original dataset. This process creates multiple subsets of your data.\n",
      "\n",
      "2. **Parallel Training:**\n",
      "\n",
      "   - A separate machine learning model (often a decision tree) is trained on each of these bootstrap samples independently.  Think of it like training many \"mini\" models in parallel.\n",
      "\n",
      "3. **Aggregation:**\n",
      "\n",
      "   - Once all the models are trained, their predictions are combined. For regression problems, this usually means averaging the predictions. For classification, it often involves majority voting (choosing the class predicted by most models).\n",
      "\n",
      "**Why Bagging Works:**\n",
      "\n",
      "- **Reduces Variance:** Bagging helps to reduce the variance of your model.  Since different bootstrap samples contain slightly different data, the individual models will have different biases. When you average their predictions, the noise is smoothed out, leading to a more stable and generalizable model.\n",
      "\n",
      "- **Combats Overfitting:** Overfitting occurs when a model learns the training data too well, capturing even random noise.  By training on diverse bootstrap samples, bagging helps prevent overfitting because each model is less likely to memorize the specific quirks of a single sample.\n",
      "\n",
      "**Popular Bagging Algorithms:**\n",
      "\n",
      "- **Random Forest:**  A widely used bagging algorithm that builds multiple decision trees and aggregates their predictions. Random forest introduces additional randomness by selecting a random subset of features at each node when building the trees.\n",
      "\n",
      "**When to Use Bagging:**\n",
      "\n",
      "- **High Variance Models:** Bagging is especially beneficial for models that tend to have high variance, such as decision trees.\n",
      "- **Noisy or Complex Data:** When your data is noisy or has complex relationships, bagging can help improve model robustness.\n",
      "\n",
      "\n",
      "Let me know if you'd like a deeper dive into a specific aspect of bagging, such as random forests or how it compares to other ensemble methods!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc20\"}}\n",
    "for r in with_message_history.stream(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Describe about bagging techniques in ML\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    print(r.content, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
