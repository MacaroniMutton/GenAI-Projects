{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "# Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F4AB178040>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F4AB08CCD0>, model_name='Gemma2-9b-It', groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"Gemma2-9b-It\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I am an AI language model, so I don't have feelings or experiences like humans do. However, I'm here and ready to assist you with any questions or tasks you may have. How can I help you today?\\n\", response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 18, 'total_tokens': 68, 'completion_time': 0.102671818, 'prompt_time': 0.0023992, 'queue_time': None, 'total_time': 0.105071018}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-26ce7a9b-b3a0-4b9e-a2df-c17e70dc1794-0', usage_metadata={'input_tokens': 18, 'output_tokens': 50, 'total_tokens': 68})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='おはようございます (Ohayou gozaimasu) \\n', response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 23, 'total_tokens': 37, 'completion_time': 0.028, 'prompt_time': 0.00245776, 'queue_time': None, 'total_time': 0.03045776}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-974c4bd1-95f1-4560-9212-210d8ee3f5a9-0', usage_metadata={'input_tokens': 23, 'output_tokens': 14, 'total_tokens': 37})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English to Japanese\"),\n",
    "    HumanMessage(content=\"Good morning\")\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'おはようございます (Ohayou gozaimasu) \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'おはようございます (ohayo gozaimasu) \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using LCEL, chain the components\n",
    "\n",
    "chain = llm|parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['lang1', 'lang2', 'text'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['lang1', 'lang2'], template='Translate the following from {lang1} to {lang2}:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt Templates\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "generic_template = \"Translate the following from {lang1} to {lang2}:\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", generic_template),\n",
    "        (\"user\", \"{text}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'],\n",
       " 'kwargs': {'input_variables': ['lang1', 'lang2', 'text'],\n",
       "  'messages': [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['lang1', 'lang2'], template='Translate the following from {lang1} to {lang2}:')),\n",
       "   HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))]},\n",
       " 'name': 'ChatPromptTemplate',\n",
       " 'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PromptInput'},\n",
       "   {'id': 1,\n",
       "    'type': 'runnable',\n",
       "    'data': {'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'],\n",
       "     'name': 'ChatPromptTemplate'}},\n",
       "   {'id': 2, 'type': 'schema', 'data': 'ChatPromptTemplateOutput'}],\n",
       "  'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English to Japanese:'), HumanMessage(content='Good Morning')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt.invoke({\"lang1\": \"English\", \"lang2\": \"Japanese\", \"text\": \"Good Morning\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English to Japanese:'),\n",
       " HumanMessage(content='Good Morning')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'おはよう (ohayou) \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt|llm|parser\n",
    "\n",
    "chain.invoke({\"lang1\": \"English\", \"lang2\": \"Japanese\", \"text\": \"Good Morning\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
